{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfeebb92",
   "metadata": {},
   "source": [
    "## MLP PURO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a511e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par√¢metros trein√°veis: 2,497\n",
      "\n",
      "=== Treinando baseline (sem otimiza√ß√µes) ===\n",
      "Epoch 01/100  - Train MSE: 6.841244\n",
      "Epoch 05/100  - Train MSE: 0.259598\n",
      "Epoch 10/100  - Train MSE: 0.256308\n",
      "Epoch 15/100  - Train MSE: 0.254737\n",
      "Epoch 20/100  - Train MSE: 0.252864\n",
      "Epoch 25/100  - Train MSE: 0.250617\n",
      "Epoch 30/100  - Train MSE: 0.255069\n",
      "Epoch 35/100  - Train MSE: 0.252574\n",
      "Epoch 40/100  - Train MSE: 0.251391\n",
      "Epoch 45/100  - Train MSE: 0.250561\n",
      "Epoch 50/100  - Train MSE: 0.249480\n",
      "Epoch 55/100  - Train MSE: 0.252669\n",
      "Epoch 60/100  - Train MSE: 0.248716\n",
      "Epoch 65/100  - Train MSE: 0.250889\n",
      "Epoch 70/100  - Train MSE: 0.251528\n",
      "Epoch 75/100  - Train MSE: 0.249430\n",
      "Epoch 80/100  - Train MSE: 0.241440\n",
      "Epoch 85/100  - Train MSE: 0.251638\n",
      "Epoch 90/100  - Train MSE: 0.244204\n",
      "Epoch 95/100  - Train MSE: 0.249912\n",
      "Epoch 100/100  - Train MSE: 0.246966\n",
      "\n",
      "üìä Baseline MLP (sem otimiza√ß√µes):\n",
      "MAE:   0.0887\n",
      "RMSE:  1.0670\n",
      "R¬≤:    0.9327\n",
      "Tempo total de infer√™ncia: 0.100602 s\n",
      "Tempo m√©dio por amostra:   0.0167 ms\n"
     ]
    }
   ],
   "source": [
    "# mlp_regressao_baseline.py\n",
    "# ============================================================\n",
    "# Regress√£o de \"Precipita√ß√£o dia\" com MLP (PyTorch) - BASELINE\n",
    "# Com SEED e LR_BASELINE para reprodutibilidade.\n",
    "# Sem poda / quantiza√ß√£o / qualquer otimiza√ß√£o.\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------- Configura√ß√£o -----------------------\n",
    "CSV_PATH = \"bd_EstacaoVargemFria_e_Pesca.csv\"\n",
    "\n",
    "EPOCHS_BASELINE = 100\n",
    "LR_BASELINE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # for√ßado CPU\n",
    "\n",
    "# ----------------------- Utilidades -----------------------\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return float(np.mean(np.abs(y_pred - y_true)))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_pred - y_true) ** 2)))\n",
    "\n",
    "def r2_score_np(y_true, y_pred):\n",
    "    ss_res = float(np.sum((y_true - y_pred) ** 2))\n",
    "    ss_tot = float(np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "    return float(1.0 - ss_res / ss_tot) if ss_tot > 0 else float(\"nan\")\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ----------------------- Dataset -----------------------\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))              # (N, F)\n",
    "        self.y = torch.from_numpy(y.astype(np.float32).reshape(-1))  # (N,)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ----------------------- Modelo -----------------------\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # (N,)\n",
    "\n",
    "# ----------------------- Treino / Avalia√ß√£o -----------------------\n",
    "def train_model(model, loader, epochs, lr):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            preds = model(xb)            # CPU\n",
    "            loss = criterion(preds, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "        epoch_loss /= len(loader.dataset)\n",
    "        if epoch % 5 == 0 or epoch == 1 or epoch == epochs:\n",
    "            print(f\"Epoch {epoch:02d}/{epochs}  - Train MSE: {epoch_loss:.6f}\")\n",
    "\n",
    "def evaluate_model(model, loader, label=\"Avalia√ß√£o\"):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            y_pred.append(preds)\n",
    "            y_true.append(yb.cpu().numpy())\n",
    "    t1 = time.time()\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "\n",
    "    _mae = mae(y_true, y_pred)\n",
    "    _rmse = rmse(y_true, y_pred)\n",
    "    _r2 = r2_score_np(y_true, y_pred)\n",
    "    total_time = t1 - t0\n",
    "    time_per_sample_ms = (total_time / len(loader.dataset)) * 1000.0\n",
    "\n",
    "    print(f\"\\nüìä {label}:\")\n",
    "    print(f\"MAE:   {_mae:.4f}\")\n",
    "    print(f\"RMSE:  {_rmse:.4f}\")\n",
    "    print(f\"R¬≤:    {_r2:.4f}\")\n",
    "    print(f\"Tempo total de infer√™ncia: {total_time:.6f} s\")\n",
    "    print(f\"Tempo m√©dio por amostra:   {time_per_sample_ms:.4f} ms\")\n",
    "\n",
    "    return _mae, _rmse, _r2, time_per_sample_ms\n",
    "\n",
    "# ----------------------- Main -----------------------\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    # ============================================================\n",
    "    # PR√â-PROCESSAMENTO (id√™ntico ao da CNN baseline)\n",
    "    # ============================================================\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df = df[df['Nome'].str.strip() == 'Esta√ß√£o Pesca - UFRPE']\n",
    "    df['Data esta√ß√£o'] = pd.to_datetime(df['Data esta√ß√£o'], errors='coerce')\n",
    "    df = df.sort_values('Data esta√ß√£o')\n",
    "    df = df.interpolate(method='linear', limit_direction='forward')\n",
    "    df['Precipita√ß√£o anterior'] = df['Precipita√ß√£o dia'].shift(1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    colunas_features = ['Temperatura', 'Umidade', 'Velocidade Vento', 'Rajada Vento', 'Precipita√ß√£o anterior']\n",
    "    coluna_saida = 'Precipita√ß√£o dia'\n",
    "    df = df[colunas_features + [coluna_saida]]\n",
    "\n",
    "    X = df[colunas_features].values\n",
    "    y = df[coluna_saida].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=SEED\n",
    "    )\n",
    "\n",
    "    train_ds = TabularDataset(X_train, y_train)\n",
    "    test_ds  = TabularDataset(X_test,  y_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # ============================================================\n",
    "    # BASELINE: treino e avalia√ß√£o\n",
    "    # ============================================================\n",
    "    model = MLPRegressor(in_features=X_train.shape[1]).to(DEVICE)\n",
    "    print(f\"Par√¢metros trein√°veis: {count_params(model):,}\")\n",
    "\n",
    "    print(\"\\n=== Treinando baseline (sem otimiza√ß√µes) ===\")\n",
    "    train_model(model, train_loader, epochs=EPOCHS_BASELINE, lr=LR_BASELINE)\n",
    "    evaluate_model(model, test_loader, label=\"Baseline MLP (sem otimiza√ß√µes)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e5442",
   "metadata": {},
   "source": [
    "## Puro com energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f06412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ab32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
